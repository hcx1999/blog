# AI基础05-对抗神经网络
## 1. 生成式模型 Generative Models
#### 计算机视觉
- 计算机图形学依赖大量 **先验知识（Prior Knowledge）** ，如材料、物理建模、光照等，来精确地生成图像。
- 统计 / 深度生成模型（Statistical/Deep Generative Model）则通过学习 **大量数据**，尝试减少对先验知识的依赖。
#### 先验知识
- **先验知识** ：在模型训练或图像生成前已经存在的知识，如物理规则或专家知识。
- **数据** ：模型训练或图像生成过程中使用的数据。
#### 生成式模型
生成模型的目的是为了 **学习数据的概率分布** $p(x)$。理解了这个分布后，我们可以通过采样（sampling）来生成新的数据样本，即 $x_{new}∼p(x)$。
**关键词**：概率分布、采样、密度估计、无监督学习
与生成式模型（Generative Models）相对的是判别式模型（Discriminator Models）
## 2. 朴素对抗神经网络 Vanilla GAN
![[attachments/Pasted image 20250513140250.png]]
### 对抗性损失 Adversarial Loss vs. 均方误差 MSE
我们可以发现，对抗学习比 MSE 更加像人类，我们通常说 **对抗学习是一种自适应的损失函数** （Adversarial loss = automatic/adaptive loss），在训练不同阶段，它能够关注不同的东西。这是因为对抗损失 **不仅考虑像素级别的相似度，还考虑了图像的整体分布**。这意味着生成的图像在整体结构和细节上都更加逼真。
### 深度卷积对抗神经网络 DCGAN
DCGAN 是一种结合了卷积神经网络（CNN）和 GAN（生成对抗网络）的深度学习模型。DCGAN 的 Generator **使用卷积神经网络来生成图像**，而判别器（Discriminator）同样使用卷积网络来判断图像是真实的还是由生成器（Generator）生成的。
除此之外，DCGAN 的创新之处还体现在它使用了一系列的技巧来稳定训练过程，如使用批归一化（Batch Normalization）、去除全连接层、使用 ReLU 激活函数等。
### 变分自编码器 VAE
![[attachments/Pasted image 20250513140854.png]]
VAE（变分自编码器）是一种生成模型，它包含一个 Encoder **将数据编码为一个潜在空间的表示**，和一个 Generator（也称为 Decoder） **将潜在空间的表示解码回数据**。
**GAN 通常能够生成比 VAE 更清晰、更逼真的图像**，因为 GAN 的对抗性损失促使生成器学习到更加精细的数据分布，而 VAE 的重构损失和 KL 散度（KLD）则可能导致生成的图像较为模糊。
- **VAE** = Generator + Encoder
- **Vanilla GAN** = Generator + Discriminator
- **Better GAN** = Generator + Discriminator + Encoder
## 3. 精选对抗神经网络
### 条件对抗神经网络（Conditional GAN, cGAN）
条件对抗神经网络是对抗神经网络（GAN）的一种扩展，它通过 **引入额外的条件信息**，控制生成内容。这种方法能够解决多模态问题，即对于同一个条件，存在多种可能的输出。
最经典的一个生成任务就是，输入希望生成的图像类别标签，然后根据这个标签来生成图像，比如控制生成花、生成鸟、或者别的东西。
#### 结构：
![[attachments/Pasted image 20250513141209.png]]
#### 应用：
![[attachments/Pasted image 20250513141236.png]]
### 寻找编码器（Find Latent Representation）
#### VAE(variational autoencoder)
VAE = Generator + Encoder
Vanilla GAN = Generator + Discriminator
![[attachments/Pasted image 20250525102449.png]]
### 双向生成对抗网络（Bidirectional GAN, BiGAN）
BiGAN = G + D + E
#### 结构
BiGAN 包括三个主要部分：生成器（G）、编码器（E）和判别器（D）。
- **生成器（G）**：接收随机噪声 $Z$，输出生成的数据 $\hat{X}$。
- **编码器（E）**：接收真实数据 $X$，输出编码表示 $\hat{Z}$。
- **判别器（D）**：用来判断输入是来自生成器的输出还是编码器的输出。
![[attachments/Pasted image 20250513142019.png]]
#### 训练过程
1. **训练生成器**：输入随机噪声 $Z$ 到生成器，生成 $\hat{X}$；同时把 $Z$ 和 $\hat{X}$ 一起给判别器。
2. **训练编码器**：输入真实数据 $X$ 到编码器，生成 $\hat{Z}$；同时把 $X$ 和 $\hat{Z}$ 一起给判别器。
3. **判别器的目标**：减小生成器和编码器输出的联合分布之间的差异。
#### 最终目标
当生成器和编码器达到最优时，编码器将成为生成器的逆函数，即$E = G^{-1}$。此时，$G(E(X))=X$和$E(G(z))=Z$。
### 协同生成对抗网络（Cooperative GAN，CoGAN）
CoGAN 可以学习两个（语义相似）领域的联合分布 p(XA,XB)p(XA​,XB​)，并且能够同时生成两个领域的数据。两个领域的数据没有已知的映射关系。
![[attachments/Pasted image 20250513142047.png]]
CoGAN 通过 **共享权重机制使得两个生成网络可以生成具有相似性质的数据**，而不需要为每个数据集训练独立的模型。
#### 主要应用：
Unpaired Image-to-Image Translation（无配对图像到图像的转换）。
#### 局限性
它在不知道映射关系的情况下学习了两个领域的联合分布，但是当给定一张图片时，它不能输出另一个领域的图片
因此，我们需要将图像映射回潜在编码以便进行更多应用。
### 循环生成对抗网络（CycleGAN）
#### 结构
![[attachments/Pasted image 20250513142149.png]]
#### 应用
引入L1 Loss（非相对loss）评估相似性，改善了BiGAN和coGAN的诸多问题，是比较新的一个GAN形式。但现在主流应用并非GAN而是扩散模型。