# 幻觉抑制课题组实习笔记
## Day1
开会。
1. 课题拆解：
	- Agent发展概况：RAG范式、workflow范式、Agent范式
	- Agent框架：李殿龙、姚顺宇、COALA
	- 幻觉本质：有损压缩，模型本质是对关联模式的编码而非对事实的编码
	- 优化方法：结构化prompt、长短期记忆、暴露置信度、复盘式自检
	![[attachments/Pasted image 20250814112022.png]]
2. Agent行动模块与ACI(Agent-Computer Interface)
	- 案例分析：SWE-Agent、MindFlow、Auto-GPT、ChatDev
	- 行动模块：动作简单性、动作效率性
3. 竞品分析报告
	- 确实挺不错的，有旁听组会的味道了，区别是能听懂（
## Day2、3、4
熟悉环境、跑代码、旅游
## Day5
参观一线工作环境，为进厂上班做好准备(x
真正生产线上LLM由于其不稳定性并没有得到很好的应用。真正参与生产的还是传统的机器学习和统计学算法。
## Day6
讲了一些Agent框架
1. MindFlow+：
2. ReAct框架：
3. Decision Transformer：

读完了一些论文，包括Agent框架、强化学习、测试集、模型微调等。
## Day7
1. 应用框架
	- 讲解了传统机器学习（老框架）在产业中的应用，包括语句编码、相似度排序等。
	- 目前准备融入LLM方法（新框架）的可能，比如上下文改写、用大模型训练小模型等。
2. Agent长期记忆
## Day8
1. 程序性知识SOP（Standard Operation Procedure）
	- 与RAG相对比，什么地方更好，什么地方可以借鉴。
> 在作报告时，介绍相关项目+观点（或者说讲自己或别人的故事）会比讲类型、应用、前景等一堆很浅的概念更好，一方面更有吸引力，另一方面听者更能问出问题来。

2. 领域模型和领域Agent
	- 微调框架：MOE、知识蒸馏、PPL、llama
	- 微调技术：LoRA、DoRA、QLoRA
		LoRA通过低秩矩阵分解实现微调，参数效率高（仅更新0.1%-1%参数）；显存占用低，适合单卡微调；通用性强，广泛支持各类模型。
		将LoRA的适配矩阵进一步分解为幅度和方向两部分独立优化。可以解耦权重学习，提升微调精度。在同等参数量下表现优于LoRA。
		4-bit量化冻结原模型，极致显存压缩支持更大模型的微调。
	![[attachments/Pasted image 20250815110132.png]]